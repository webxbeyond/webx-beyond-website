---
title: অপ্টিমাইজার ও ব্যাকপ্রপাগেশন
icon: solar:alt-arrow-right-bold-duotone
---

## অপ্টিমাইজার কী?

অপ্টিমাইজার হচ্ছে এমন একটি অ্যালগরিদম, যা নিউরাল নেটওয়ার্কের ওজন (weights) ও বায়াস (bias) আপডেট করে—লস (error) কমানোর জন্য। PyTorch-এ অপ্টিমাইজার ব্যবহার করে মডেলকে শেখানো হয়।

_অ্যানালজি:_ অপ্টিমাইজারকে ভাবুন—একজন কোচ, যিনি প্রতিটি ভুল ধরিয়ে দেন এবং শেখার পদ্ধতি ঠিক করে দেন, যাতে খেলোয়াড় (মডেল) আরও ভালো হয়।

## সাধারণ PyTorch অপ্টিমাইজার
- `torch.optim.SGD`: Stochastic Gradient Descent
- `torch.optim.Adam`: Adaptive Moment Estimation
- `torch.optim.RMSprop`: Root Mean Square Propagation

### উদাহরণ:
```python
import torch.optim as optim
optimizer = optim.Adam(model.parameters(), lr=0.001)
```

## ব্যাকপ্রপাগেশন কী?

ব্যাকপ্রপাগেশন (Backpropagation) হচ্ছে এমন একটি পদ্ধতি, যা লস ফাংশনের গ্রেডিয়েন্ট হিসাব করে ওজন আপডেট করে। অটোগ্রাড দিয়ে গ্রেডিয়েন্ট বের হয়, অপ্টিমাইজার দিয়ে ওজন আপডেট হয়।

_অ্যানালজি:_ ব্যাকপ্রপাগেশনকে ভাবুন—একটি পরীক্ষার পরে শিক্ষক ভুলগুলো দেখিয়ে দেন, ছাত্র সেই ভুলগুলো ঠিক করে আবার চেষ্টা করে।

## ট্রেনিং লুপে অপ্টিমাইজার ও ব্যাকপ্রপাগেশন

```python
for data, target in dataloader:
    optimizer.zero_grad()      # পুরনো গ্রেডিয়েন্ট রিসেট
    output = model(data)       # ফরওয়ার্ড পাস
    loss = loss_fn(output, target)  # লস হিসাব
    loss.backward()            # ব্যাকপ্রপাগেশন—গ্রেডিয়েন্ট হিসাব
    optimizer.step()           # ওজন আপডেট
```

## অপ্টিমাইজার কনফিগারেশন
- `lr` (learning rate): শেখার গতি
- `momentum`: পুরনো গ্রেডিয়েন্টের প্রভাব
- `weight_decay`: রেগুলারাইজেশন

### উদাহরণ:
```python
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
```

## রিয়েল-ওয়ার্ল্ড উদাহরণ

ধরা যাক, আপনি একটি ফুল ক্লাসিফিকেশন মডেল ট্রেইন করছেন। প্রতিটি ব্যাচে অপ্টিমাইজার ও ব্যাকপ্রপাগেশন দিয়ে মডেল আরও ভালো হয়।

## সতর্কতা ও টিপস
- `optimizer.zero_grad()` না দিলে গ্রেডিয়েন্ট অ্যাকুমুলেট হয়—ভুল ফলাফল আসতে পারে।
- Learning rate বেশি হলে মডেল overshoot করতে পারে, কম হলে শেখা ধীর হয়।
- Adam সাধারণত দ্রুত converge করে, SGD বেশি কাস্টমাইজযোগ্য।

## সংক্ষিপ্ত চেকলিস্ট
- অপ্টিমাইজার তৈরি করুন: SGD, Adam, RMSprop
- ট্রেনিং লুপে zero_grad → forward → loss → backward → step
- Learning rate ও অন্যান্য প্যারামিটার ঠিক করুন

## উপসংহার

অপ্টিমাইজার ও ব্যাকপ্রপাগেশন—নিউরাল নেটওয়ার্ক শেখার মূল ইঞ্জিন। এগুলো ভালোভাবে বুঝলে, PyTorch-এ যেকোনো মডেল দক্ষভাবে ট্রেইন করতে পারবেন।

_পরবর্তী পাঠে: বেসিক নিউরাল নেটওয়ার্ক বানানো (MLP)—হাতেকলমে কোড!_
